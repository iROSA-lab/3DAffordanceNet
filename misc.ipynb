{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from os.path import join as opj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load partnet info txt file:\n",
    "anno_info_path = 'utils/partnet_all_valid_anno_info.txt'\n",
    "anno_info = np.loadtxt(anno_info_path, dtype=str)\n",
    "# load as dict based on sem_class\n",
    "anno_info_dict = {}\n",
    "for line in anno_info:\n",
    "    anno_info_dict[line[3]] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeid_to_partnet_dir = dict()\n",
    "# loop through the whole new_aff_dataset\n",
    "for cls in new_aff_dataset['semantic_classes']:\n",
    "    for shapeid in new_aff_dataset['data'][cls].keys():\n",
    "        # lookup shapeid in anno_info_dict\n",
    "        anno_id = anno_info_dict[shapeid][0]\n",
    "        # add anno_id to dataset\n",
    "        new_aff_dataset['data'][cls][shapeid]['partnet_anno_id'] = anno_id\n",
    "        # also save it in a separate dict\n",
    "        shapeid_to_partnet_dir[shapeid] = anno_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dict to json file\n",
    "import json\n",
    "with open('shapeid_to_partnet_dir.json', 'w') as f:\n",
    "    # make sure there are line breaks\n",
    "    json.dump(shapeid_to_partnet_dir, f)\n",
    "\n",
    "# Save new dataset\n",
    "new_aff_path = opj(data_root, 'anntd_remapped_full_shape_val_data.pkl')\n",
    "with open(new_aff_path, 'wb') as f:\n",
    "    pkl.dump(new_aff_dataset, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
